{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution\n",
    "</div>\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "sum(data[data.race=='w'].call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad</th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>honors</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>empholes</th>\n",
       "      <th>occupspecific</th>\n",
       "      <th>...</th>\n",
       "      <th>compreq</th>\n",
       "      <th>orgreq</th>\n",
       "      <th>manuf</th>\n",
       "      <th>transcom</th>\n",
       "      <th>bankreal</th>\n",
       "      <th>trade</th>\n",
       "      <th>busservice</th>\n",
       "      <th>othservice</th>\n",
       "      <th>missind</th>\n",
       "      <th>ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nonprofit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ad  education  ofjobs  yearsexp  honors  volunteer  military  empholes  \\\n",
       "0  b  1          4       2         6       0          0         0         1   \n",
       "1  b  1          3       3         6       0          1         1         0   \n",
       "2  b  1          4       1         6       0          0         0         0   \n",
       "3  b  1          3       4         6       0          1         0         1   \n",
       "4  b  1          3       3        22       0          0         0         0   \n",
       "\n",
       "   occupspecific    ...      compreq  orgreq  manuf  transcom  bankreal trade  \\\n",
       "0             17    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "1            316    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "2             19    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "3            313    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "4            313    ...          1.0     1.0    0.0       0.0       0.0   0.0   \n",
       "\n",
       "  busservice othservice  missind  ownership  \n",
       "0        0.0        0.0      0.0             \n",
       "1        0.0        0.0      0.0             \n",
       "2        0.0        0.0      0.0             \n",
       "3        0.0        0.0      0.0             \n",
       "4        0.0        1.0      0.0  Nonprofit  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 1\n",
    "If we are only interested in whether or not particular sounding names have an impact on the request for interviews, we have a couple of options we can think about using. This first would be a chi-squared test that would examine whether or not there are significant differences in the proportions between the two groups. We could also perform a bootstrap version in which we compare the distributions of the proportions against permutation samples. This would mean that the distributions would represent the distribution of a particular race group receiving a folllow up interview. We could also perform independent samples t-test to measure the proportions of each race group, or we could find the z-score of in the difference of proportions between the two race groups. If we pursued the difference in proportion z-score, we could also run bootstrap samples to find the true distribution of that difference and figure out where our difference resides in that distribution. If we wished to involve the covariates that are also present in the data set, we could provide a more comprehensive relationship between the covariates, the predictor, and the outcome variables. If we adopted a more research-oriented causal framework, we would want to test the relationship between each covariate on both the predictor and outcome variables to uncover any possible confounding variables. We could then utilize a logistic regression for the variables and hopefully provide a causal understanding between race and job application success. On the other hand, if we adopted a more predictive method, in which we would like to predict which individual would receive an interview and compare the importance of racial group to the other features, we could some machine learning algorithm like a random forest and extract the important features.\n",
    "\n",
    "The central limit theorem does apply. We can either think of the distribution as the proportion for any individual regardless of racial background to continue to the next stage in hiring process, we can think of the distribution for the proportions of the white or black sounding names, or we could think about the difference in the proportion between the two racial groups. Any one of these distributions will abide by the central limit theorem, that any sample from these distributions will begin to take on a normal distribution as the sample size approaches infinity with an approximation of the population test statistic that was used and an approximation of the population standard deviation.\n",
    "\n",
    "\n",
    "#### Question 2\n",
    "Ho: The proportion for white sounding names who receive request for an interview is equal to the proportion of black sounding names who receive request for an interview( P(I| W-name) = P(I|B-name) ) \n",
    "\n",
    "Ha: The proportion for white sounding names who receive request for an interview is NOT equal to the proportion of black sounding names who receive request for an interview( P(I| W-name) =/= P(I|B-name) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = data[data.race=='w']\n",
    "b = data[data.race=='b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "##### Part A\n",
    "###### Bootstrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black confidence interval & margin of error: [0.0550308  0.07433265] , 0.009445585310459137\n",
      "white confidence interval & margin of error: [0.08501027 0.10841889] , 0.011498972773551941\n",
      "pvalue for differences in proportinos: 1e-05\n"
     ]
    }
   ],
   "source": [
    "white_callback = np.mean(w.call)\n",
    "black_callback = np.mean(b.call)\n",
    "dif_callback = white_callback - black_callback\n",
    "replicates = np.empty(100000)\n",
    "whites = np.empty(100000)\n",
    "blacks = np.empty(100000)\n",
    "for i in range(100000):\n",
    "    samples = np.random.permutation(data.call)\n",
    "    white = np.random.choice(w.call, size = len(w))\n",
    "    black = np.random.choice(b.call, size = len(b))\n",
    "    perm_white = samples[:len(w)]\n",
    "    perm_black = samples[len(w):]\n",
    "    replicates[i] = np.mean(perm_white) - np.mean(perm_black)\n",
    "    whites[i] = np.mean(white)\n",
    "    blacks[i] = np.mean(black)\n",
    "pvalue = np.sum(replicates >= dif_callback)/len(replicates)\n",
    "black_ci = np.percentile(blacks, [2.5, 97.5])\n",
    "white_ci = np.percentile(whites, [2.5, 97.5])\n",
    "white_moe = white_callback - white_ci[0]\n",
    "black_moe = black_callback - black_ci[0]\n",
    "print(\"black confidence interval & margin of error: \" + str(black_ci) + \" , \" +  str(black_moe))\n",
    "print(\"white confidence interval & margin of error: \" + str(white_ci) + \" , \" +  str(white_moe))\n",
    "print(\"pvalue for differences in proportinos: \" + str(pvalue))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a probability of 1 in 100,000 of getting the observed difference in proportions if the null hypothesis, that the proportions between racial groups are the same, is true. We have reason to reject the null hypothesis and have evidence to support that white sounding names get, on average, more call backs than black sounding names. If we look at the confidence intervals for each racial group, we see no overlap, which is another way of demonstrating statistical significance at an alpha level of 0.05 since the confidence intervals are 95% confidence intervals. These are saying that there is a 95% chance that the true proportions for racial groups are between the bracketed values. Since the values do not overlap, we are led to believe that the true proportions are not equivalents, and otherwise, rejecting our null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "##### Part B\n",
    "###### Frequentist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.108412235238472\n",
      "1.991942704752209e-05\n",
      "proportion difference conf interval: 0.016777448506376254 , 0.0472882612037449\n",
      "proportion difference margin of error: 0.015255406348684322\n"
     ]
    }
   ],
   "source": [
    "w_se = np.sqrt((white_callback*(1-white_callback))/len(w))\n",
    "w_moe = w_se * 1.96\n",
    "b_se = np.sqrt((black_callback*(1-black_callback))/len(b))\n",
    "b_moe = b_se* 1.96\n",
    "overall_prop = (np.sum(w.call) + np.sum(b.call))/(len(w)+len(b))\n",
    "zscore = (dif_callback - 0)/np.sqrt(overall_prop*(1-overall_prop)*((1/len(w))+(1/len(b))))\n",
    "print(zscore)\n",
    "pvalue = stats.norm.sf(abs(zscore))\n",
    "print(pvalue)\n",
    "upper = (white_callback - black_callback) + 1.96*(np.sqrt((white_callback*(1-white_callback)/len(w))+(black_callback*(1-black_callback))/len(b)))\n",
    "lower = (white_callback - black_callback) - 1.96*(np.sqrt((white_callback*(1-white_callback)/len(w))+(black_callback*(1-black_callback))/len(b)))\n",
    "print(\"proportion difference conf interval: \" + str(lower) + \" , \" +  str(upper))\n",
    "se_dif = np.sqrt(w_se**2 + b_se**2)\n",
    "moe = se_dif * 1.96\n",
    "print('proportion difference margin of error: ' + str(moe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we utilize the frequentist approach, we decide to calculate the confidence interval and margin of error of the difference in proportions as opposed to the individual racial groups. This time we should see a 0 value in the confidence interval if we wish to fail to reject the null hypothesis. However, we see small values but values that indicate the true mean difference in the proportions to be between those two values with 95% confidence. Once more, we have a probability of about 1 in 100,000 of observing our results and thus have evidence to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-statistic - confidence interval of the proportions\n",
    "#(t, p) = stats.ttest_ind(w.call, b.call, equal_var=False)\n",
    "#print(t, p)\n",
    "#w_upper = white_callback + w_moe\n",
    "#w_lower = white_callback - w_moe\n",
    "#b_upper = black_callback + b_moe\n",
    "#b_lower = black_callback - b_moe\n",
    "#print('white name conf interval: ' + str(w_lower) + \" , \" + str(w_upper))\n",
    "#print('white margin of error: ' + str(w_moe))\n",
    "#print('black name conf interval: ' + str(b_lower) + \" , \" + str(b_upper))\n",
    "#print('black margin of error: ' + str(b_moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "We see, through multiple methods, that black sounding names are less likely to receive a call back for an interview. We believe that the true proportion of black sounding names that receive interview callbacks to be between about 5.5% and 7.4%. This is different from white sounding names that we believe to have a true proportion of interview call backs to be between 8.5% and 10.8%. We want to be careful to point to any causal factors too early. However, the statistical significance indicates that we would only see a proportion difference of this magnitude 1 in 100,000 if the null hypothesis that the true proportion difference is 0 is true. Since this event seems rare, we reject the null hypothesis and believe there to be some difference between these two groups.\n",
    "\n",
    "#### Question 5\n",
    "Now, to further explain these differences, we need further examine any confounding covariates that might better explain this relationship. For now, we are assuming all covariates are randomly distributed between white and black sounding names, which leads us to believe that a white or black sounding names informs a hiring manages first impression and subsequent judgements. If the covariates are truly randomly distributed, then we might be able to take our statistical significance one step further into a causal explanation. Since we assume that years of experiences or educational attainment are equally distributed, we should see equal levels of hiring based upon these equivalent levels of merit, and since we don't see equal levels of hiring under the assumption of randomly distributed covariates, then we might think this permeates all industries and all locations. Our analysis does not mean that race or name is the most important feature in receiving a call back. There are hundreds of other covariates that could better explain why a person receives a call back such as that years of experience or highest level of education. We should even further understand as to whether or not these proportions are equivalent across all industries or geographies, or if there are particular outliers that are affecting this data. We are simply saying that if those other covariates are held at a constant, we would expect to see on average, a higher proportion of white sounding names receive interview call backs. With 95% confidence, this true proportion difference between 1.6 and 4.7 is also practically significant since it would be extremely unfair for any individual to not be considered based upon their merits any percent of the time.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
